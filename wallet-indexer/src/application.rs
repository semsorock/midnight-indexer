// This file is part of midnight-indexer.
// Copyright (C) 2025 Midnight Foundation
// SPDX-License-Identifier: Apache-2.0
// Licensed under the Apache License, Version 2.0 (the "License");
// You may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use crate::domain::{Wallet, storage::Storage};
use anyhow::Context;
use fastrace::trace;
use futures::{Stream, StreamExt, TryStreamExt, future::ok, stream};
use indexer_common::domain::{BlockIndexed, NetworkId, Publisher, Subscriber, WalletIndexed};
use itertools::Itertools;
use log::debug;
use serde::Deserialize;
use std::{
    num::NonZeroUsize,
    sync::{
        Arc,
        atomic::{AtomicU64, Ordering},
    },
    time::Duration,
};
use tokio::{select, task};

#[derive(Debug, Clone, Deserialize)]
pub struct Config {
    pub network_id: NetworkId,

    #[serde(with = "humantime_serde")]
    pub active_wallets_repeat_delay: Duration,

    #[serde(with = "humantime_serde")]
    pub active_wallets_ttl: Duration,

    pub transaction_batch_size: NonZeroUsize,

    #[serde(default = "parallelism_default")]
    pub parallelism: NonZeroUsize,
}

pub async fn run(
    config: Config,
    storage: impl Storage,
    publisher: impl Publisher,
    subscriber: impl Subscriber,
) -> anyhow::Result<()> {
    let Config {
        network_id,
        active_wallets_repeat_delay,
        active_wallets_ttl,
        transaction_batch_size,
        parallelism,
    } = config;

    // Shared atomic counter for the maximum transaction ID seen in BlockIndexed events. This allows
    // Wallet Indexer to skip database queries when it is already up-to-date. Updated by the
    // block_indexed_task, read by index_wallet tasks.
    let max_transaction_id = Arc::new(AtomicU64::new(0));

    let block_indexed_task = task::spawn({
        let subscriber = subscriber.clone();
        let max_transaction_id = max_transaction_id.clone();

        async move {
            let block_indexed_stream = subscriber.subscribe::<BlockIndexed>();

            block_indexed_stream
                .try_for_each(|block_indexed| {
                    if let Some(id) = block_indexed.max_transaction_id {
                        max_transaction_id.store(id, Ordering::Release);
                    }
                    ok(())
                })
                .await
                .context("cannot get next BlockIndexed event")?;

            Ok::<(), anyhow::Error>(())
        }
    });

    let index_wallets_task = {
        task::spawn(async move {
            active_wallets(active_wallets_repeat_delay, active_wallets_ttl, &storage)
                .map(|result| result.context("get next active wallet"))
                .try_for_each_concurrent(Some(parallelism.get()), |wallet| {
                    let max_transaction_id = max_transaction_id.clone();
                    let mut publisher = publisher.clone();
                    let mut storage = storage.clone();

                    async move {
                        index_wallet(
                            wallet,
                            transaction_batch_size,
                            network_id,
                            max_transaction_id,
                            &mut publisher,
                            &mut storage,
                        )
                        .await
                    }
                })
                .await
        })
    };

    select! {
        result = block_indexed_task => result,
        result = index_wallets_task => result,
    }?
}

fn active_wallets(
    active_wallets_repeat_delay: Duration,
    active_wallets_ttl: Duration,
    storage: &impl Storage,
) -> impl Stream<Item = Result<Wallet, sqlx::Error>> + '_ {
    tokio_stream::StreamExt::throttle(stream::repeat(()), active_wallets_repeat_delay)
        .map(|_| Ok::<_, sqlx::Error>(()))
        .and_then(move |_| storage.active_wallets(active_wallets_ttl))
        .map_ok(|wallets| stream::iter(wallets).map(Ok))
        .try_flatten()
}

#[trace]
async fn index_wallet(
    wallet: Wallet,
    transaction_batch_size: NonZeroUsize,
    network_id: NetworkId,
    max_transaction_id: Arc<AtomicU64>,
    publisher: &mut impl Publisher,
    storage: &mut impl Storage,
) -> anyhow::Result<()> {
    // Only access with storage if possibly needed.
    if wallet.last_indexed_transaction_id < max_transaction_id.load(Ordering::Acquire) {
        let session_id = wallet.viewing_key.to_session_id();

        let tx = storage
            .acquire_lock(session_id)
            .await
            .context("acquire lock")?;

        match tx {
            Some(mut tx) => {
                debug!(session_id:%; "indexing wallet");

                let from = wallet.last_indexed_transaction_id + 1;
                let transactions = storage
                    .get_transactions(from, transaction_batch_size, &mut tx)
                    .await
                    .context("get transactions")?;

                let last_indexed_transaction_id = transactions.iter().map(|t| t.id).max();
                let Some(last_indexed_transaction_id) = last_indexed_transaction_id else {
                    debug!(session_id:%; "no transactions for wallet");
                    return Ok(());
                };

                let relevant_transactions = transactions
                    .into_iter()
                    .map(|transaction| {
                        transaction
                            .relevant(&wallet, network_id)
                            .context("check transaction relevance")
                            .map(|relevant| (relevant, transaction))
                    })
                    .filter_map_ok(|(relevant, transaction)| relevant.then_some(transaction))
                    .collect::<Result<Vec<_>, _>>()?;

                storage
                    .save_relevant_transactions(
                        &wallet.viewing_key,
                        &relevant_transactions,
                        last_indexed_transaction_id,
                        &mut tx,
                    )
                    .await
                    .context("save relevant transactions")?;

                tx.commit().await.context("commit database transaction")?;
                debug!(session_id:%, from, transaction_batch_size; "wallet indexed");

                if !relevant_transactions.is_empty() {
                    publisher
                        .publish(&WalletIndexed { session_id })
                        .await
                        .context("cannot publish WalletIndexed event")?;
                }
            }

            None => {
                debug!(session_id:%; "not handling wallet");
            }
        }
    }

    Ok(())
}

fn parallelism_default() -> NonZeroUsize {
    std::thread::available_parallelism().unwrap_or(NonZeroUsize::MIN)
}
